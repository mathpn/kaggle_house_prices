{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(corrplot)\n",
    "library(ggplot2)\n",
    "library(tidyr)\n",
    "library(dplyr)\n",
    "library(purrr)\n",
    "library(GGally)\n",
    "library(MASS)\n",
    "library(caret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll analyze the Kaggle House Prices dataset and predict the prices of houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_data <- read.csv(\"data/train.csv\")\n",
    "test_data <- read.csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by taking at look at which variables are available in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "str(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a mix of numerical and categorical variables with missing values. Let's take a look at the sale price variable, which is the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "qplot(train_data$SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that the distribution of SalePrice has a positive skew and is not exactly normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=20, repr.plot.height=20)\n",
    "nums <- unlist(lapply(train_data, is.numeric), use.names = FALSE)\n",
    "train_data %>% select_if(is.numeric) %>%  gather(cols, value) %>%  ggplot(aes(value)) + geom_histogram() + facet_wrap(~cols, scales='free')\n",
    "options(repr.plot.width=12, repr.plot.height=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, many variables are not normally distributed. Also, many of them seem to be count variables with discrete values. Some have very strong skew and kurtosis, while others have zero-inflated distributions. These facts are important to understand before fitting a model.\n",
    "\n",
    "Let's also have a look at correlation matrix plots to see if we can spot some obvious or interesting correlations. We'll use Spearman correlation since most variables are not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_data %>% select_if(is.numeric) %>% cor(use = \"complete.obs\", method = \"spearman\") -> correlations\n",
    "corrplot(correlations, method = \"circle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some variables seem to provide little extra information over others, for example, YearBuilt and GarageYrBlt. This means there is quite a lot of multicolinearity in the data. This is very relevant if we want to fit a linear model.\n",
    "\n",
    "Let's finally take a look at the variables with the highest correlation with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "correlations[, 38] %>% sort(decreasing = TRUE) %>% print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall quality, ground living area, year built, garage capacity and the number of full bathrooms are the variables most correlated with the target variable.\n",
    "\n",
    "Let's take a look at the number of levels of each categorical variable. Variables with only two levels are transformed to numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_data <- as.data.frame(unclass(train_data), stringsAsFactors = TRUE)\n",
    "\n",
    "train_data$Street <- as.numeric(train_data$Street)\n",
    "train_data$Alley <- as.numeric(train_data$Alley)\n",
    "train_data$Utilities <- as.numeric(train_data$Utilities)\n",
    "train_data$CentralAir <- as.numeric(train_data$CentralAir)\n",
    "\n",
    "\n",
    "# test data\n",
    "test_data <- as.data.frame(unclass(test_data), stringsAsFactors = TRUE)\n",
    "\n",
    "test_data$Street <- as.numeric(test_data$Street)\n",
    "test_data$Alley <- as.numeric(test_data$Alley)\n",
    "test_data$Utilities <- as.numeric(test_data$Utilities)\n",
    "test_data$CentralAir <- as.numeric(test_data$CentralAir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "lapply(train_data, is.na) %>% sapply(sum) %>% sapply(function(x) x / 1460) %>% sort(decreasing = TRUE) -> na_proportion\n",
    "\n",
    "print(na_proportion[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll simply remove the variables with more than 20% of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_data_cleaned <- subset(train_data, select = -c(PoolQC, MiscFeature, Alley, Fence, FireplaceQu))\n",
    "\n",
    "test_data_cleaned <- subset(test_data, select = -c(PoolQC, MiscFeature, Alley, Fence, FireplaceQu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the variables with the highest correlation with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "correlations[, 38] %>% sort(decreasing = TRUE) %>% names() -> cols\n",
    "train_data_cleaned %>% dplyr::select(cols[0:10]) %>% ggpairs(aes(alpha = 0.75)) + theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first column, we can see that in fact those variables seem to be positively correlated with the target variable. However, only overall quality seems to be reasonably normally distributed. Let's take a look at their distributions and transform them to get more normal-like distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=6, repr.plot.height=6)\n",
    "\n",
    "qqnorm(train_data_cleaned$SalePrice)\n",
    "qqline(train_data_cleaned$SalePrice)\n",
    "\n",
    "train_data_cleaned$SalePriceLog <- log(train_data_cleaned$SalePrice)\n",
    "qqnorm(train_data_cleaned$SalePriceLog)\n",
    "qqline(train_data_cleaned$SalePriceLog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "qqnorm(train_data_cleaned$GrLivArea)\n",
    "qqline(train_data_cleaned$GrLivArea)\n",
    "\n",
    "train_data_cleaned$GrLivAreaLog <- log(train_data_cleaned$GrLivArea)\n",
    "test_data_cleaned$GrLivAreaLog <- log(test_data_cleaned$GrLivArea)\n",
    "qqnorm(train_data_cleaned$GrLivAreaLog)\n",
    "qqline(train_data_cleaned$GrLivAreaLog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "qqnorm(train_data_cleaned$YearBuilt)\n",
    "qqline(train_data_cleaned$YearBuilt)\n",
    "\n",
    "train_data_cleaned$YearBuiltLogInv <- log(1 / train_data_cleaned$YearBuilt)\n",
    "test_data_cleaned$YearBuiltLogInv <- log(1 / test_data_cleaned$YearBuilt)\n",
    "qqnorm(train_data_cleaned$YearBuiltLogInv)\n",
    "qqline(train_data_cleaned$YearBuiltLogInv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is so skewed the transformation is not enough to make it normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "qqnorm(train_data_cleaned$GarageArea)\n",
    "qqline(train_data_cleaned$GarageArea)\n",
    "\n",
    "train_data_cleaned$GarageAreaLog <- log(train_data_cleaned$GarageArea + 1)\n",
    "test_data_cleaned$GarageAreaLog <- log(test_data_cleaned$GarageArea + 1)\n",
    "qqnorm(train_data_cleaned$GarageAreaLog)\n",
    "qqline(train_data_cleaned$GarageAreaLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this one has a lot of zeros, we'll create a new variable indicating if a garage is present or not. We'll also turn the zero values into NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_data_cleaned$GaragePresent <- as.numeric(train_data_cleaned$GarageArea > 0)\n",
    "train_data_cleaned$GarageAreaLog <- ifelse(train_data_cleaned$GaragePresent, train_data_cleaned$GarageAreaLog, NA)\n",
    "summary(train_data_cleaned$GarageAreaLog)\n",
    "summary(train_data_cleaned$GaragePresent)\n",
    "\n",
    "test_data_cleaned$GaragePresent <- as.numeric(test_data_cleaned$GarageArea > 0)\n",
    "test_data_cleaned$GarageAreaLog <- ifelse(test_data_cleaned$GaragePresent, train_data_cleaned$GarageAreaLog, NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "qqnorm(train_data_cleaned$GarageYrBlt)\n",
    "qqline(train_data_cleaned$GarageYrBlt)\n",
    "\n",
    "train_data_cleaned$GarageYrBltLogInv <- log(1 / train_data_cleaned$GarageYrBlt)\n",
    "test_data_cleaned$GarageYrBltLogInv <- log(1 / test_data_cleaned$GarageYrBlt)\n",
    "qqnorm(train_data_cleaned$GarageYrBltLogInv)\n",
    "qqline(train_data_cleaned$GarageYrBltLogInv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "qqnorm(train_data_cleaned$TotalBsmtSF)\n",
    "qqline(train_data_cleaned$TotalBsmtSF)\n",
    "\n",
    "train_data_cleaned$TotalBsmtSFLog <- log(1 + train_data_cleaned$TotalBsmtSF)\n",
    "test_data_cleaned$TotalBsmtSFLog <- log(1 + test_data_cleaned$TotalBsmtSF)\n",
    "qqnorm(train_data_cleaned$TotalBsmtSFLog)\n",
    "qqline(train_data_cleaned$TotalBsmtSFLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, it's useful to create a new variable indicating if a basement is present or not and turn zeros into NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_data_cleaned$BasementPresent <- as.numeric(train_data_cleaned$TotalBsmtSF > 0)\n",
    "train_data_cleaned$TotalBsmtSFLog <- ifelse(train_data_cleaned$BasementPresent, train_data_cleaned$TotalBsmtSFLog, NA)\n",
    "summary(train_data_cleaned$TotalBsmtSFLog)\n",
    "summary(train_data_cleaned$BasementPresent)\n",
    "\n",
    "test_data_cleaned$BasementPresent <- as.numeric(test_data_cleaned$TotalBsmtSF > 0)\n",
    "test_data_cleaned$TotalBsmtSFLog <- ifelse(test_data_cleaned$BasementPresent, train_data_cleaned$TotalBsmtSFLog, NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(cols)\n",
    "\n",
    "qplot(train_data_cleaned$YearRemodAdd, train_data_cleaned$SalePrice, geom = \"point\")\n",
    "qqnorm(train_data_cleaned$YearRemodAdd)\n",
    "qqline(train_data_cleaned$YearRemodAdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is again too skewed and there's also a suspicious excess of 1950s in this variable. For this reason, We'll binarize this variable around 1985 (by visual inspection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_data_cleaned$YearRemodAddBinary <- as.numeric(train_data_cleaned$YearRemodAdd >= 1985)\n",
    "summary(train_data_cleaned$YearRemodAddBinary)\n",
    "\n",
    "test_data_cleaned$YearRemodAddBinary <- as.numeric(test_data_cleaned$YearRemodAdd >= 1985)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "qqnorm(train_data_cleaned$X1stFlrSF)\n",
    "qqline(train_data_cleaned$X1stFlrSF)\n",
    "\n",
    "train_data_cleaned$X1stFlrSFLog <- log(train_data_cleaned$X1stFlrSF)\n",
    "test_data_cleaned$X1stFlrSFLog <- log(test_data_cleaned$X1stFlrSF)\n",
    "qqnorm(train_data_cleaned$X1stFlrSFLog)\n",
    "qqline(train_data_cleaned$X1stFlrSFLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, now we have a data table with transformed variables and some new ones for those that are most correlated with the target variable. Let's visualize again the correlation patterns between the target variables and the transformed variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=12, repr.plot.height=12)\n",
    "\n",
    "transformed_cols = c(\n",
    "    \"SalePriceLog\", \"OverallQual\", \"GrLivAreaLog\",\n",
    "    \"YearBuiltLogInv\", \"GarageCars\", \"FullBath\",\n",
    "    \"GarageAreaLog\", \"GarageYrBltLogInv\", \"TotalBsmtSFLog\",\n",
    "    \"YearRemodAddBinary\", \"X1stFlrSFLog\")\n",
    "\n",
    "train_data_cleaned %>% dplyr::select(transformed_cols) %>% ggpairs(aes(alpha = 0.75)) + theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column looks better now with the transformed variables. Let's split the data into train and validation sets and then fit a simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(42)\n",
    "split_index <- caret::createDataPartition(train_data_cleaned$SalePriceLog, p = 0.8, list = FALSE)\n",
    "train_data_cleaned_train <- train_data_cleaned[split_index,]\n",
    "train_data_cleaned_val <- train_data_cleaned[-split_index,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "formula <- paste(\"SalePrice ~ \", paste(transformed_cols, collapse = \" + \"), sep = \"\")\n",
    "\n",
    "linear_model <- lm(formula, data = train_data_cleaned_train)\n",
    "\n",
    "summary(linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the root mean squared error, which is the metric used in this competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "(predict(linear_model, train_data_cleaned_val) - train_data_cleaned_val$SalePriceLog) %>% mean(na.rm = TRUE) %>% sqrt() -> lm_rmse\n",
    "print(lm_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the correlation plots we can see there's quite some multicolinearity happening here. Still, the model doesn't seem all that bad with R^2 = 0.91. Let's add the categorical variables to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_data_cleaned_train %>% select_if(purrr::negate(is.numeric)) %>% names() -> categorical_cols\n",
    "\n",
    "lm_cols = c(transformed_cols, categorical_cols)\n",
    "\n",
    "formula <- paste(\"SalePrice ~ \", paste(lm_cols, collapse = \" + \"), sep = \"\")\n",
    "\n",
    "linear_model <- lm(formula, data = train_data_cleaned_train)\n",
    "\n",
    "summary(linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_data_complete <- tidyr::drop_na(train_data_cleaned_train)\n",
    "val_data_complete <- tidyr::drop_na(train_data_cleaned_val)\n",
    "\n",
    "(predict(linear_model, train_data_complete) - train_data_complete$SalePriceLog) %>% mean(na.rm = TRUE) %>% sqrt() -> lm_rmse\n",
    "print(lm_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here train data is used for simplicity since there are many categorical variables whose levels are not the same in both train and validation data.\n",
    "\n",
    "RÂ² is now 0.95. However, we should take this with a grain of salt since there are far too many categorical variables and levels and too much multicolinearity. It's a good idea to either use a form of variable selection such as lasso or another type of model that can implicitly handle the excess of variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
